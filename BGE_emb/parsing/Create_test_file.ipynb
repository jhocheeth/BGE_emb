{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0753c1ee-ea4a-40d8-867e-b15d20aef63d",
   "metadata": {},
   "source": [
    "Add random negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53867f5e-989f-471f-b71e-6f3e97062c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Clinical_Trial_Triplet_v3/Test/SY_triplets.jsonl'\n",
    "output_file_path = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Clinical_Trial_Triplet_v3/Test/SY_triplets_w_neg.jsonl'\n",
    "\n",
    "# Load the input data\n",
    "with open(input_file_path, 'r') as infile:\n",
    "    lines = infile.readlines()\n",
    "    data = [json.loads(line) for line in lines]\n",
    "\n",
    "# Group entries by category\n",
    "categories = {}\n",
    "for entry in data:\n",
    "    entry['neg'] = entry['pos']  # Assign pos value to neg\n",
    "    category = entry['category']\n",
    "    if category not in categories:\n",
    "        categories[category] = []\n",
    "    categories[category].append(entry)\n",
    "\n",
    "# Shuffle neg terms within each category\n",
    "for category, entries in categories.items():\n",
    "    neg_pool = [entry['neg'][0] for entry in entries]  # Collect all neg terms in a list\n",
    "    random.shuffle(neg_pool)  # Shuffle the neg terms\n",
    "    for i, entry in enumerate(entries):\n",
    "        entry['neg'] = [neg_pool[i]]  # Assign the shuffled neg term back to the entry\n",
    "\n",
    "# Write the modified data to the output file\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    for entry in data:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11872133-57d9-4bc6-9f4d-75eff130c390",
   "metadata": {},
   "source": [
    "Create test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7177b87-906f-4531-896c-c871d01c9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# File paths\n",
    "input_file = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Clinical_Trial_Triplet_v3/Test/SY_triplets_w_neg.jsonl'\n",
    "output_pairs_file = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Triplet_AUC/pos_SY_triplets.csv'\n",
    "output_neg_pairs_file = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Triplet_AUC/neg_SY_triplets.csv'\n",
    "output_unique_file = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Triplet_AUC/U_terms_SY_triplets.csv'\n",
    "\n",
    "# Reading JSONL and extracting query, positive pairs, and negative pairs\n",
    "max_entries = 200000\n",
    "data = []\n",
    "neg_data = []\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            item = json.loads(line)\n",
    "            query = item.get('query')\n",
    "            positives = item.get('pos')\n",
    "            negatives = item.get('neg')\n",
    "            if isinstance(query, str):\n",
    "                if isinstance(positives, list):\n",
    "                    for positive in positives:\n",
    "                        if isinstance(positive, str):\n",
    "                            data.append([query, positive])\n",
    "                if isinstance(negatives, list):\n",
    "                    for negative in negatives:\n",
    "                        if isinstance(negative, str):\n",
    "                            neg_data.append([query, negative])\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "# Select n random entries for positive and negative pairs\n",
    "if len(data) > max_entries:\n",
    "    data = random.sample(data, max_entries)\n",
    "if len(neg_data) > max_entries:\n",
    "    neg_data = random.sample(neg_data, max_entries)\n",
    "\n",
    "# Creating DataFrames and saving to CSV\n",
    "df = pd.DataFrame(data, columns=['desc1', 'desc2'])\n",
    "df.dropna(subset=['desc1', 'desc2'], inplace=True)  # Drop rows with NaN or empty cells\n",
    "\n",
    "df_neg = pd.DataFrame(neg_data, columns=['desc1', 'desc2'])\n",
    "df_neg.dropna(subset=['desc1', 'desc2'], inplace=True)  # Drop rows with NaN or empty cells\n",
    "\n",
    "# Cleaning text - removing dots and non-string elements\n",
    "df['desc1'] = df['desc1'].apply(lambda x: x.replace('.', '') if isinstance(x, str) else x)\n",
    "df['desc2'] = df['desc2'].apply(lambda x: x.replace('.', '') if isinstance(x, str) else x)\n",
    "df = df[df['desc1'].apply(lambda x: isinstance(x, str)) & df['desc2'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "df_neg['desc1'] = df_neg['desc1'].apply(lambda x: x.replace('.', '') if isinstance(x, str) else x)\n",
    "df_neg['desc2'] = df_neg['desc2'].apply(lambda x: x.replace('.', '') if isinstance(x, str) else x)\n",
    "df_neg = df_neg[df_neg['desc1'].apply(lambda x: isinstance(x, str)) & df_neg['desc2'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Save the cleaned positive pairs to CSV\n",
    "df.to_csv(output_pairs_file, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Save the cleaned negative pairs to CSV\n",
    "df_neg.to_csv(output_neg_pairs_file, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print the length of the cleaned pairs\n",
    "print(f\"Number of cleaned positive pairs: {len(df)}\")\n",
    "print(f\"Number of cleaned negative pairs: {len(df_neg)}\")\n",
    "\n",
    "# Extract unique elements from both desc1 and desc2 (for positives and negatives)\n",
    "unique_terms = pd.concat([df['desc1'], df['desc2'], df_neg['desc1'], df_neg['desc2']]).unique()\n",
    "unique_df = pd.DataFrame(unique_terms, columns=['Common_Groups'])\n",
    "\n",
    "# Saving unique elements to CSV\n",
    "unique_df.dropna(subset=['Common_Groups'], inplace=True)  # Drop rows with NaN\n",
    "unique_df.to_csv(output_unique_file, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print the length of unique elements\n",
    "print(f\"Number of unique elements: {len(unique_terms)}\")\n",
    "\n",
    "print(\"Processing complete. Files saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f96dcf-31b2-46d3-b123-b73c30aa8147",
   "metadata": {},
   "source": [
    "View file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6379-db37-44cd-b421-4f4782925f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSONL data from the file\n",
    "input_file = '/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Clinical_Trial_Triplet_v3/Test/SY_triplets.jsonl'\n",
    "\n",
    "# Read all lines from the input file\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Print the length of the file\n",
    "print(f'Number of entries in the file: {len(lines)}')\n",
    "\n",
    "# Print the head of the file (first 5 entries)\n",
    "for i in range(min(200, len(lines))):\n",
    "    print(json.loads(lines[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa9f83-f977-4642-889a-20f1fecf1595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
